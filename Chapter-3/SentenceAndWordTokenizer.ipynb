{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import gutenberg\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "alice = gutenberg.raw(fileids='carroll-alice.txt')\n",
    "sample_text = 'We will discuss briefly about the basic syntax, structure and design philosophies. There is a defined hierarchical syntax for Python code which you should remember when writing code! Python is a really powerful programming language!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144395\n"
     ]
    }
   ],
   "source": [
    "print len(alice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Alice's Adventures in Wonderland by Lewis Carroll 1865]\n",
      "\n",
      "CHAPTER I. Down the Rabbit-Hole\n",
      "\n",
      "Alice was\n"
     ]
    }
   ],
   "source": [
    "print alice[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "default_st = nltk.sent_tokenize\n",
    "alice_sentences = default_st(text = alice)\n",
    "sample_sentences = default_st(text=sample_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sentences in sample_text: 3\n",
      "Sample text sentences :-\n",
      "['We will discuss briefly about the basic syntax, structure and design philosophies.',\n",
      " 'There is a defined hierarchical syntax for Python code which you should remember when writing code!',\n",
      " 'Python is a really powerful programming language!']\n",
      "\n",
      "Total sentences in alice: 1625\n",
      "First 5 sentences in alice:-\n",
      "[u\"[Alice's Adventures in Wonderland by Lewis Carroll 1865]\\n\\nCHAPTER I.\",\n",
      " u\"Down the Rabbit-Hole\\n\\nAlice was beginning to get very tired of sitting by her sister on the\\nbank, and of having nothing to do: once or twice she had peeped into the\\nbook her sister was reading, but it had no pictures or conversations in\\nit, 'and what is the use of a book,' thought Alice 'without pictures or\\nconversation?'\",\n",
      " u'So she was considering in her own mind (as well as she could, for the\\nhot day made her feel very sleepy and stupid), whether the pleasure\\nof making a daisy-chain would be worth the trouble of getting up and\\npicking the daisies, when suddenly a White Rabbit with pink eyes ran\\nclose by her.',\n",
      " u\"There was nothing so VERY remarkable in that; nor did Alice think it so\\nVERY much out of the way to hear the Rabbit say to itself, 'Oh dear!\",\n",
      " u'Oh dear!']\n"
     ]
    }
   ],
   "source": [
    "print 'Total sentences in sample_text:', len(sample_sentences)\n",
    "print 'Sample text sentences :-'\n",
    "pprint(sample_sentences)\n",
    "print '\\nTotal sentences in alice:', len(alice_sentences)\n",
    "print 'First 5 sentences in alice:-'\n",
    "pprint(alice_sentences[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157171\n",
      " \n",
      "Wiederaufnahme der Sitzungsperiode Ich erkläre die am Freitag , dem 17. Dezember unterbrochene Sit\n"
     ]
    }
   ],
   "source": [
    "#tokenizing in German\n",
    "\n",
    "from nltk.corpus import europarl_raw\n",
    "german_text = europarl_raw.german.raw(fileids='ep-00-01-17.de')\n",
    "#Total characters\n",
    "print len(german_text)\n",
    "#First 100 characters\n",
    "print german_text[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'nltk.tokenize.punkt.PunktSentenceTokenizer'>\n"
     ]
    }
   ],
   "source": [
    "german_sentences_def = default_st(text=german_text, language='german')\n",
    "#loading german text tokenizer into a PunktSentenceTokenizer instance\n",
    "\n",
    "german_tokenizer = nltk.data.load(resource_url='tokenizers/punkt/german.pickle')\n",
    "german_sentences = german_tokenizer.tokenize(german_text)\n",
    "\n",
    "#verify the type of german_tokenizer\n",
    "#should be PunktSentenceTokenizer\n",
    "\n",
    "print type(german_tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus we see that indeed the german_tokenizer is an instance of PunktSentenceTokenizer, which is specialized in dealing with the German language. Next we check whether the sentences obtained from the default tokenizer are the\n",
    "same as the sentences obtained by this pre-trained tokenizer, and ideally it should be True. We also print some sample tokenized sentences from the output after that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      " \n",
      "Wiederaufnahme der Sitzungsperiode Ich erkläre die am Freitag , dem 17. Dezember unterbrochene Sitzungsperiode des Europäischen Parlaments für wiederaufgenommen , wünsche Ihnen nochmals alles Gute zum Jahreswechsel und hoffe , daß Sie schöne Ferien hatten .\n",
      "Wie Sie feststellen konnten , ist der gefürchtete \" Millenium-Bug \" nicht eingetreten .\n",
      "Doch sind Bürger einiger unserer Mitgliedstaaten Opfer von schrecklichen Naturkatastrophen geworden .\n",
      "Im Parlament besteht der Wunsch nach einer Aussprache im Verlauf dieser Sitzungsperiode in den nächsten Tagen .\n",
      "Heute möchte ich Sie bitten - das ist auch der Wunsch einiger Kolleginnen und Kollegen - , allen Opfern der Stürme , insbesondere in den verschiedenen Ländern der Europäischen Union , in einer Schweigeminute zu gedenken .\n"
     ]
    }
   ],
   "source": [
    "print german_sentences_def == german_sentences\n",
    "for sent in german_sentences[0:5]:\n",
    "    print sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['We will discuss briefly about the basic syntax, structure and design philosophies.',\n",
      " 'There is a defined hierarchical syntax for Python code which you should remember when writing code!',\n",
      " 'Python is a really powerful programming language!']\n"
     ]
    }
   ],
   "source": [
    "#using RegExpTokenizer\n",
    "\n",
    "SENTENCE_TOKENS_PATTERN = r'(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<![A-Z]\\.)(?<=\\.|\\?|\\!)\\s'\n",
    "regex_st = nltk.tokenize.RegexpTokenizer(pattern=SENTENCE_TOKENS_PATTERN, gaps = True)\n",
    "sample_sentences = regex_st.tokenize(sample_text)\n",
    "pprint(sample_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'brown', 'fox', 'was', \"n't\", 'that', 'quick', 'and', 'he', 'could', \"n't\", 'win', 'the', 'race']\n"
     ]
    }
   ],
   "source": [
    "#Word Tokenization\n",
    "\n",
    "sentence =\"The brown fox wasn't that quick and he couldn't win the race\"\n",
    "\n",
    "default_wt = nltk.word_tokenize\n",
    "words = default_wt(sentence)\n",
    "print words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
